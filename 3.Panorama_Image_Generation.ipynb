{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations\n",
    "\n",
    "CFG = {\n",
    "    'ratio': 0.85,\n",
    "    'min_match': 10,\n",
    "    'smoothing_window_size': 100,\n",
    "    'estimation_thresh': 0.60\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs sift algorithm to find features\n",
    "\n",
    "def findFeatures(img):\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(img, None)\n",
    "\n",
    "    return keypoints, descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matches features given a list of keypoints, descriptors, and images\n",
    "\n",
    "def matchFeatures(desc1, desc2):\n",
    "    matcher = cv2.BFMatcher()\n",
    "    matches = matcher.knnMatch(desc1, desc2, k=2)\n",
    "    \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computers a homography from 4-correspondences\n",
    "# referred from: https://www.youtube.com/watch?v=l_qjO4cM74o&t=573s\n",
    "\n",
    "def calculateHomography(correspondences):\n",
    "    # loop through correspondences and create assemble matrix\n",
    "    aList = []\n",
    "    for corr in correspondences:\n",
    "        p1 = np.matrix([corr.item(0), corr.item(1), 1])\n",
    "        p2 = np.matrix([corr.item(2), corr.item(3), 1])\n",
    "\n",
    "        a1 = [p1.item(0), p1.item(1), 1, 0, 0, 0, -p2.item(0)*p1.item(0), -p2.item(0)*p1.item(1), -p2.item(0)]\n",
    "        a2 = [0, 0, 0, p1.item(0), p1.item(1), 1, -p2.item(1)*p1.item(0), -p2.item(1)*p1.item(1), -p2.item(1)]\n",
    "        \n",
    "        aList.append(a1)\n",
    "        aList.append(a2)\n",
    "\n",
    "    matrixA = np.matrix(aList)\n",
    "\n",
    "    # svd composition\n",
    "    u, s, v = np.linalg.svd(matrixA)\n",
    "\n",
    "    # reshape the min singular value into a 3 by 3 matrix\n",
    "    h = np.reshape(v[8], (3, 3))\n",
    "\n",
    "    # normalize\n",
    "    h = (1/h.item(8)) * h\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the geometric distance (error) between estimated points and original points\n",
    "\n",
    "def geometricDistance(correspondence, h):\n",
    "\n",
    "    p1 = np.transpose(np.matrix([correspondence[0].item(0), correspondence[0].item(1), 1]))\n",
    "    estimatep2 = np.dot(h, p1)\n",
    "    estimatep2 = (1/estimatep2.item(2))*estimatep2\n",
    "\n",
    "    p2 = np.transpose(np.matrix([correspondence[0].item(2), correspondence[0].item(3), 1]))\n",
    "    error = p2 - estimatep2\n",
    "    return np.linalg.norm(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs through ransac algorithm, creating homographies from random correspondences\n",
    "\n",
    "def ransac(corr, thresh):\n",
    "    maxInliers = []\n",
    "    finalH = None\n",
    "    for i in range(1000):\n",
    "        # find 4 random points to calculate a homography\n",
    "        randomFour = corr[random.randrange(0, len(corr))]\n",
    "        for j in range(3):\n",
    "            corr_add = corr[random.randrange(0, len(corr))]\n",
    "            randomFour = np.vstack((randomFour, corr_add))\n",
    "\n",
    "        h = calculateHomography(randomFour)\n",
    "        \n",
    "        inliers = []\n",
    "        error_list = []\n",
    "        for i in range(len(corr)):\n",
    "            d = geometricDistance(corr[i], h)\n",
    "            error_list.append(d)\n",
    "            if d < 5:\n",
    "                inliers.append(corr[i])\n",
    "\n",
    "        if len(inliers) > len(maxInliers):\n",
    "            maxInliers = inliers\n",
    "            finalH = h\n",
    "        print(\"Corr size: \", len(corr), \" NumInliers: \", len(inliers), \"Max inliers: \", len(maxInliers))\n",
    "\n",
    "        if len(maxInliers) > (len(corr)*thresh):\n",
    "            break\n",
    "\n",
    "    return finalH, maxInliers, error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(img1, img2, version):\n",
    "    height_img1 = img1.shape[0]\n",
    "    width_img1 = img1.shape[1]\n",
    "    width_img2 = img2.shape[1]\n",
    "    \n",
    "    height_panorama = height_img1\n",
    "    width_panorama = width_img1 + width_img2\n",
    "    offset = int(CFG['smoothing_window_size'] / 2)\n",
    "    barrier = img1.shape[1] - int(CFG['smoothing_window_size'] / 2)\n",
    "    mask = np.zeros((height_panorama, width_panorama))\n",
    "    \n",
    "    if version== 'left_image':\n",
    "        mask[:, barrier - offset:barrier + offset ] = np.tile(np.linspace(1, 0, 2 * offset ).T, (height_panorama, 1))\n",
    "        mask[:, :barrier - offset] = 1\n",
    "    else:\n",
    "        mask[:, barrier - offset :barrier + offset ] = np.tile(np.linspace(0, 1, 2 * offset ).T, (height_panorama, 1))\n",
    "        mask[:, barrier + offset:] = 1\n",
    "    return cv2.merge([mask, mask, mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blending(img1, img2, homography):\n",
    "    height_img1 = img1.shape[0]\n",
    "    width_img1 = img1.shape[1]\n",
    "    width_img2 = img2.shape[1]\n",
    "    height_panorama = height_img1\n",
    "    width_panorama = width_img1 + width_img2\n",
    "\n",
    "    mask1 = create_mask(img1, img2, version='left_image')\n",
    "    panorama1 = np.zeros((height_panorama, width_panorama, 3))\n",
    "    panorama1[0:img1.shape[0], 0:img1.shape[1], :] = img1\n",
    "    panorama1 *= mask1\n",
    "    \n",
    "    mask2 = create_mask(img1, img2, version='right_image')\n",
    "    panorama2 = cv2.warpPerspective(img2, homography, (width_panorama, height_panorama))*mask2\n",
    "    \n",
    "    result = panorama1 + panorama2\n",
    "\n",
    "    rows, cols = np.where(result[:, :, 0] != 0)\n",
    "    min_row, max_row = min(rows), max(rows) + 1\n",
    "    min_col, max_col = min(cols), max(cols) + 1\n",
    "    final_result = result[min_row:max_row, min_col:max_col, :]\n",
    "    return final_result, panorama1, panorama2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('./img/img_1111.jpg') # query image\n",
    "img2 = cv2.imread('./img/img_2222.jpg') # train image_1\n",
    "img3 = cv2.imread('./img/img_3333.jpg') # train image_2\n",
    "\n",
    "list_img = []\n",
    "list_img.appned(img1)\n",
    "list_img.appned(img2)\n",
    "list_img.appned(img3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in list_img:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found keypoints in img1: 18618\n",
      "Found keypoints in img2: 12081\n",
      "Corr size:  3579  NumInliers:  2146 Max inliers:  2146\n",
      "Corr size:  3579  NumInliers:  960 Max inliers:  2146\n",
      "Corr size:  3579  NumInliers:  6 Max inliers:  2146\n",
      "Corr size:  3579  NumInliers:  5 Max inliers:  2146\n",
      "Corr size:  3579  NumInliers:  1111 Max inliers:  2146\n",
      "Corr size:  3579  NumInliers:  13 Max inliers:  2146\n",
      "Corr size:  3579  NumInliers:  5 Max inliers:  2146\n",
      "Corr size:  3579  NumInliers:  5 Max inliers:  2146\n",
      "Corr size:  3579  NumInliers:  1579 Max inliers:  2146\n",
      "Corr size:  3579  NumInliers:  11 Max inliers:  2146\n",
      "Corr size:  3579  NumInliers:  1361 Max inliers:  2146\n",
      "Corr size:  3579  NumInliers:  2417 Max inliers:  2417\n",
      "Final homography:  [[ 5.02572133e-01 -2.85981138e-02  5.19894482e+02]\n",
      " [-1.35733174e-01  8.49962053e-01  5.28621483e+01]\n",
      " [-3.79981011e-04  1.79658399e-05  1.00000000e+00]]\n",
      "Final inliers count:  2417\n"
     ]
    }
   ],
   "source": [
    "for idx in range(len(list_img)):\n",
    "    if img is not None:\n",
    "        kp1, desc1 = findFeatures(img)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #find features and keypoints\n",
    "    correspondenceList = []\n",
    "    if img1 is not None and img2 is not None:\n",
    "        # find features\n",
    "        kp1, desc1 = findFeatures(img1)\n",
    "        kp2, desc2 = findFeatures(img2)\n",
    "        print(\"Found keypoints in \" + 'img1' + \": \" + str(len(kp1)))\n",
    "        print(\"Found keypoints in \" + 'img2' + \": \" + str(len(kp2)))\n",
    "        keypoints = [kp1, kp2]\n",
    "        \n",
    "        # match features \n",
    "        matches = matchFeatures(desc1, desc2)\n",
    "        \n",
    "        good_points = []\n",
    "        good_matches=[]\n",
    "        for m1, m2 in matches:\n",
    "            if m1.distance < CFG['ratio'] * m2.distance:\n",
    "                good_points.append((m1.trainIdx, m1.queryIdx))\n",
    "                good_matches.append([m1])\n",
    "        \n",
    "        img3 = cv2.drawMatchesKnn(img1, kp1, img2, kp2, good_matches, None, flags=2)\n",
    "        cv2.imwrite('matching.jpg', img3)\n",
    "        \n",
    "        if len(good_points) > CFG['min_match']:       \n",
    "            for (i, j) in good_points:\n",
    "                (x1, y1) = kp1[j].pt\n",
    "                (x2, y2) = kp2[i].pt\n",
    "                correspondenceList.append([x2, y2, x1, y1])\n",
    "\n",
    "        corrs = np.matrix(correspondenceList)\n",
    "\n",
    "        # find homography using ransac algorithm\n",
    "        finalH, inliers, error_list = ransac(corrs, CFG['estimation_thresh'])\n",
    "        print(\"Final homography: \", finalH)\n",
    "        print(\"Final inliers count: \", len(inliers))\n",
    "\n",
    "        f = open('homography.txt', 'w')\n",
    "        f.write(\"Final homography: \\n\" + str(finalH)+\"\\n\")\n",
    "        f.write(\"Final inliers count: \" + str(len(inliers)))\n",
    "        f.close()\n",
    "    else:\n",
    "        print(\"Failed to load images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output, pano1, pano2 = blending(img1, img2, finalH)\n",
    "\n",
    "cv2.imwrite('pano1.jpg', pano1)\n",
    "cv2.imwrite('pano2.jpg', pano2)\n",
    "cv2.imwrite('panorama.jpg', output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05439ba550cafed953466942d10876816fc09d965f0b6a738ee7de8354d2d287"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
