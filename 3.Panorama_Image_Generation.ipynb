{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import getopt\n",
    "import sys\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio=0.85\n",
    "min_match=10\n",
    "smoothing_window_size=800\n",
    "estimation_thresh = 0.60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Runs sift algorithm to find features\n",
    "#\n",
    "def findFeatures(img):\n",
    "    print(\"Finding Features...\")\n",
    "    sift=cv2.xfeatures2d.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(img, None)\n",
    "\n",
    "    img = cv2.drawKeypoints(img, keypoints, img)\n",
    "    cv2.imwrite('sift_keypoints.png', img)\n",
    "\n",
    "    return keypoints, descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Matches features given a list of keypoints, descriptors, and images\n",
    "#\n",
    "def matchFeatures(kp1, kp2, desc1, desc2, img1, img2):\n",
    "    print(\"Matching Features...\")    \n",
    "    matcher = cv2.BFMatcher()\n",
    "    matches = matcher.knnMatch(desc1, desc2, k=2)\n",
    "    \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Computers a homography from 4-correspondences\n",
    "#\n",
    "def calculateHomography(correspondences):\n",
    "    #loop through correspondences and create assemble matrix\n",
    "    aList = []\n",
    "    for corr in correspondences:\n",
    "        p1 = np.matrix([corr.item(0), corr.item(1), 1])\n",
    "        p2 = np.matrix([corr.item(2), corr.item(3), 1])\n",
    "\n",
    "        a1 = [p1.item(0), p1.item(1), 1, 0, 0, 0, -p2.item(0)*p1.item(0), -p2.item(0)*p1.item(1), -p2.item(0)]\n",
    "        a2 = [0, 0, 0, p1.item(0), p1.item(1), 1, -p2.item(1)*p1.item(0), -p2.item(1)*p1.item(1), -p2.item(1)]\n",
    "        \n",
    "        aList.append(a1)\n",
    "        aList.append(a2)\n",
    "\n",
    "    matrixA = np.matrix(aList)\n",
    "\n",
    "    #svd composition\n",
    "    u, s, v = np.linalg.svd(matrixA)\n",
    "\n",
    "    #reshape the min singular value into a 3 by 3 matrix\n",
    "    h = np.reshape(v[8], (3, 3))\n",
    "\n",
    "    #normalize and now we have h\n",
    "    h = (1/h.item(8)) * h\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#Calculate the geometric distance between estimated points and original points\n",
    "#\n",
    "def geometricDistance(correspondence, h):\n",
    "\n",
    "    p1 = np.transpose(np.matrix([correspondence[0].item(0), correspondence[0].item(1), 1]))\n",
    "    estimatep2 = np.dot(h, p1)\n",
    "    estimatep2 = (1/estimatep2.item(2))*estimatep2\n",
    "\n",
    "    p2 = np.transpose(np.matrix([correspondence[0].item(2), correspondence[0].item(3), 1]))\n",
    "    error = p2 - estimatep2\n",
    "    return np.linalg.norm(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#Runs through ransac algorithm, creating homographies from random correspondences\n",
    "#\n",
    "def ransac(corr, thresh):\n",
    "    maxInliers = []\n",
    "    finalH = None\n",
    "    for i in range(1000):\n",
    "        #find 4 random points to calculate a homography\n",
    "        corr1 = corr[random.randrange(0, len(corr))]\n",
    "        corr2 = corr[random.randrange(0, len(corr))]\n",
    "        randomFour = np.vstack((corr1, corr2))\n",
    "        corr3 = corr[random.randrange(0, len(corr))]\n",
    "        randomFour = np.vstack((randomFour, corr3))\n",
    "        corr4 = corr[random.randrange(0, len(corr))]\n",
    "        randomFour = np.vstack((randomFour, corr4))\n",
    "\n",
    "        #call the homography function on those points\n",
    "        h = calculateHomography(randomFour)\n",
    "        inliers = []\n",
    "        error_list = []\n",
    "\n",
    "        for i in range(len(corr)):\n",
    "            d = geometricDistance(corr[i], h)\n",
    "            error_list.append(d)\n",
    "            if d < 5:\n",
    "                inliers.append(corr[i])\n",
    "\n",
    "        if len(inliers) > len(maxInliers):\n",
    "            maxInliers = inliers\n",
    "            finalH = h\n",
    "        print(\"Corr size: \", len(corr), \" NumInliers: \", len(inliers), \"Max inliers: \", len(maxInliers))\n",
    "\n",
    "        if len(maxInliers) > (len(corr)*thresh):\n",
    "            break\n",
    "\n",
    "    return finalH, maxInliers, error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(img1,img2,version):\n",
    "    height_img1 = img1.shape[0]\n",
    "    width_img1 = img1.shape[1]\n",
    "    width_img2 = img2.shape[1]\n",
    "    height_panorama = height_img1\n",
    "    width_panorama = width_img1 +width_img2\n",
    "    offset = int(smoothing_window_size / 2)\n",
    "    barrier = img1.shape[1] - int(smoothing_window_size / 2)\n",
    "    mask = np.zeros((height_panorama, width_panorama))\n",
    "    if version== 'left_image':\n",
    "        mask[:, barrier - offset:barrier + offset ] = np.tile(np.linspace(1, 0, 2 * offset ).T, (height_panorama, 1))\n",
    "        mask[:, :barrier - offset] = 1\n",
    "    else:\n",
    "        mask[:, barrier - offset :barrier + offset ] = np.tile(np.linspace(0, 1, 2 * offset ).T, (height_panorama, 1))\n",
    "        mask[:, barrier + offset:] = 1\n",
    "    return cv2.merge([mask, mask, mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blending(img1,img2):\n",
    "    ### 추가 ###\n",
    "    H = finalH\n",
    "    #H = registration(img1,img2)\n",
    "\n",
    "    print(f'H:{H}')\n",
    "    height_img1 = img1.shape[0]\n",
    "    width_img1 = img1.shape[1]\n",
    "    width_img2 = img2.shape[1]\n",
    "    height_panorama = height_img1\n",
    "    width_panorama = width_img1 +width_img2\n",
    "\n",
    "    panorama1 = np.zeros((height_panorama, width_panorama, 3))\n",
    "    mask1 = create_mask(img1,img2,version='left_image')\n",
    "    panorama1[0:img1.shape[0], 0:img1.shape[1], :] = img1\n",
    "    panorama1 *= mask1\n",
    "    mask2 = create_mask(img1,img2,version='right_image')\n",
    "    panorama2 = cv2.warpPerspective(img2, H, (width_panorama, height_panorama))*mask2\n",
    "    panorama3 = cv2.warpPerspective(img2, H, (width_panorama, height_panorama))\n",
    "    result=panorama1+panorama2\n",
    "\n",
    "    rows, cols = np.where(result[:, :, 0] != 0)\n",
    "    min_row, max_row = min(rows), max(rows) + 1\n",
    "    min_col, max_col = min(cols), max(cols) + 1\n",
    "    final_result = result[min_row:max_row, min_col:max_col, :]\n",
    "    return final_result, panorama1, panorama2, panorama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Features...\n",
      "Finding Features...\n",
      "Found keypoints in img1: 13806\n",
      "Found keypoints in img2: 12089\n",
      "Matching Features...\n",
      "Corr size:  2792  NumInliers:  126 Max inliers:  126\n",
      "Corr size:  2792  NumInliers:  1273 Max inliers:  1273\n",
      "Corr size:  2792  NumInliers:  1423 Max inliers:  1423\n",
      "Corr size:  2792  NumInliers:  88 Max inliers:  1423\n",
      "Corr size:  2792  NumInliers:  2116 Max inliers:  2116\n",
      "Final homography:  [[ 5.07189829e-01 -4.82657045e-02  5.27734329e+02]\n",
      " [-1.20198636e-01  8.28147688e-01  5.81084774e+01]\n",
      " [-3.65804403e-04  2.59249826e-06  1.00000000e+00]]\n",
      "Final inliers count:  2116\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Main parses argument list and runs the functions\n",
    "#\n",
    "\n",
    "#query image\n",
    "img1 = cv2.imread('./img/img_31.jpg', 0)\n",
    "#train image\n",
    "img2 = cv2.imread('./img/img_32.jpg', 0)\n",
    "\n",
    "#find features and keypoints\n",
    "correspondenceList = []\n",
    "if img1 is not None and img2 is not None:\n",
    "    kp1, desc1 = findFeatures(img1)\n",
    "    kp2, desc2 = findFeatures(img2)\n",
    "    print(\"Found keypoints in \" + 'img1' + \": \" + str(len(kp1)))\n",
    "    print(\"Found keypoints in \" + 'img2' + \": \" + str(len(kp2)))\n",
    "    keypoints = [kp1,kp2]\n",
    "    matches = matchFeatures(kp1, kp2, desc1, desc2, img1, img2)\n",
    "    \n",
    "    ### 추가 ###\n",
    "    good_points = []\n",
    "    good_matches=[]\n",
    "    for m1, m2 in matches:\n",
    "        if m1.distance < ratio * m2.distance:\n",
    "            good_points.append((m1.trainIdx, m1.queryIdx))\n",
    "            good_matches.append([m1])\n",
    "    \n",
    "    img3 = cv2.drawMatchesKnn(img1, kp1, img2, kp2, good_matches, None, flags=2)\n",
    "    cv2.imwrite('matching.jpg', img3)\n",
    "    \n",
    "    if len(good_points) > min_match:       \n",
    "        for (i, j) in good_points:\n",
    "            (x1, y1) = kp1[j].pt\n",
    "            (x2, y2) = kp2[i].pt\n",
    "            correspondenceList.append([x2, y2, x1, y1])\n",
    "\n",
    "    corrs = np.matrix(correspondenceList)\n",
    "\n",
    "    #run ransac algorithm\n",
    "    finalH, inliers, error_list = ransac(corrs, estimation_thresh)\n",
    "    print(\"Final homography: \", finalH)\n",
    "    print(\"Final inliers count: \", len(inliers))\n",
    "\n",
    "    f = open('homography.txt', 'w')\n",
    "    f.write(\"Final homography: \\n\" + str(finalH)+\"\\n\")\n",
    "    f.write(\"Final inliers count: \" + str(len(inliers)))\n",
    "    f.close()\n",
    "else:\n",
    "    print(\"Failed to load images\")\n",
    "    # print(f'error: {error_list}')\n",
    "\n",
    "###여기까지 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('./img/img_31.jpg')\n",
    "img2 = cv2.imread('./img/img_32.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H:[[ 5.07189829e-01 -4.82657045e-02  5.27734329e+02]\n",
      " [-1.20198636e-01  8.28147688e-01  5.81084774e+01]\n",
      " [-3.65804403e-04  2.59249826e-06  1.00000000e+00]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final, pano1, pano2, pano3 = blending(img1, img2)\n",
    "\n",
    "cv2.imwrite('pano1.jpg', pano1)\n",
    "cv2.imwrite('pano2.jpg', pano2)\n",
    "cv2.imwrite('pano3.jpg', pano3)\n",
    "cv2.imwrite('panorama.jpg', final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a90aeebcf29d64a654773811cc170cb25061cb2498f10ac689db374c7bf325de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
